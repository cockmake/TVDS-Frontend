# å¯¼å…¥å¿…è¦çš„Pythonæ¨¡å—
import os
from glob import glob
import requests
import re
import pandas as pd  # ç”¨äºå¤„ç†è¡¨æ ¼æ•°æ®
from datetime import datetime
import time
import threading
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

def find_info_files(folder_path):
    """
    åœ¨è½¦æ¬¡æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾ä¿¡æ¯æ–‡ä»¶
    
    å‚æ•°è¯´æ˜ï¼š
    :param folder_path: è½¦æ¬¡æ–‡ä»¶å¤¹è·¯å¾„
    
    è¿”å›å€¼ï¼š
    :return: æ‰¾åˆ°çš„ä¿¡æ¯æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    
    åŠŸèƒ½è¯´æ˜ï¼š
    åœ¨è½¦æ¬¡æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾åŒ…å«è½¦è¾†ä¿¡æ¯çš„æ–‡ä»¶
    å¯èƒ½æ˜¯Excelæ–‡ä»¶ã€CSVæ–‡ä»¶æˆ–å…¶ä»–æ ¼å¼
    """
    info_files = []
    
    # æŸ¥æ‰¾å¯èƒ½çš„ä¿¡æ¯æ–‡ä»¶
    patterns = [
        "*.xlsx",  # Excelæ–‡ä»¶
        "*.xls",   # æ—§ç‰ˆExcelæ–‡ä»¶
        "*.csv",   # CSVæ–‡ä»¶
        "*ä¿¡æ¯*.txt",  # åŒ…å«"ä¿¡æ¯"çš„æ–‡æœ¬æ–‡ä»¶
        "*åˆ—è½¦*.txt",  # åŒ…å«"åˆ—è½¦"çš„æ–‡æœ¬æ–‡ä»¶
    ]
    
    for pattern in patterns:
        files = glob(os.path.join(folder_path, pattern))
        info_files.extend(files)
    
    return info_files

def parse_vehicle_info_from_file(file_path):
    """
    ä»ä¿¡æ¯æ–‡ä»¶ä¸­è§£æè½¦è¾†æ•°æ®
    
    å‚æ•°è¯´æ˜ï¼š
    :param file_path: ä¿¡æ¯æ–‡ä»¶è·¯å¾„
    
    è¿”å›å€¼ï¼š
    :return: (è½¦è¾†ç¼–å·å­—å…¸, åˆ—è½¦åŸºæœ¬ä¿¡æ¯å­—å…¸)
    
    åŠŸèƒ½è¯´æ˜ï¼š
    æ ¹æ®æ–‡ä»¶ç±»å‹ï¼Œè§£æè½¦è¾†ç¼–å·å’Œåˆ—è½¦åŸºæœ¬ä¿¡æ¯
    """
    file_ext = os.path.splitext(file_path)[1].lower()
    
    try:
        if file_ext in ['.xlsx', '.xls']:
            # å¤„ç†Excelæ–‡ä»¶
            return parse_excel_file(file_path)
        elif file_ext == '.csv':
            # å¤„ç†CSVæ–‡ä»¶
            return parse_csv_file(file_path)
        elif file_ext == '.txt':
            # å¤„ç†æ–‡æœ¬æ–‡ä»¶
            return parse_text_file(file_path)
        else:
            print(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
            return {}, {}
    except Exception as e:
        print(f"è§£ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return {}, {}

def parse_excel_file(file_path):
    """
    è§£æExcelæ–‡ä»¶ä¸­çš„è½¦è¾†ä¿¡æ¯
    
    å‚æ•°è¯´æ˜ï¼š
    :param file_path: Excelæ–‡ä»¶è·¯å¾„
    
    è¿”å›å€¼ï¼š
    :return: (è½¦è¾†ç¼–å·å­—å…¸, åˆ—è½¦åŸºæœ¬ä¿¡æ¯å­—å…¸)
    
    åŠŸèƒ½è¯´æ˜ï¼š
    ä»Excelæ–‡ä»¶ä¸­æå–è½¦è¾†ç¼–å·è¡¨å’Œåˆ—è½¦åŸºæœ¬ä¿¡æ¯
    é€‚é…æ–°çš„Excelæ ¼å¼ï¼šç¬¬ä¸€å¼ è¡¨ä¸ºåˆ—è½¦ä¿¡æ¯ï¼Œç¬¬äºŒå¼ è¡¨ä¸ºè½¦è¾†ä¿¡æ¯
    """
    try:
        # è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
        excel_file = pd.ExcelFile(file_path)
        
        vehicle_numbers = {}
        train_info = {}
        
        # å¤„ç†ç¬¬ä¸€å¼ è¡¨ï¼šåˆ—è½¦ä¿¡æ¯
        if len(excel_file.sheet_names) >= 1:
            first_sheet = excel_file.sheet_names[0]
            
            # è¯»å–æ—¶ä¸ä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºåˆ—åï¼Œè¿™æ ·å¯ä»¥è¯»å–åˆ°å®é™…çš„è¡¨å¤´
            df1 = pd.read_excel(file_path, sheet_name=first_sheet, header=None)
            
            # ä»ç¬¬ä¸€å¼ è¡¨æå–åˆ—è½¦åŸºæœ¬ä¿¡æ¯
            # éå†æ‰€æœ‰å•å…ƒæ ¼ï¼ŒæŸ¥æ‰¾åŒ…å«å…³é”®ä¿¡æ¯çš„å†…å®¹
            for i, row in df1.iterrows():
                for j, cell in enumerate(row):
                    if pd.notna(cell):
                        cell_str = str(cell).strip()
                        
                        # æå–è½¦æ¬¡ä¿¡æ¯ï¼ˆæŸ¥æ‰¾åŒ…å«Kã€Tã€Gç­‰è½¦æ¬¡å·çš„å†…å®¹ï¼‰
                        if re.search(r'[KGTD]\d+', cell_str):
                            match = re.search(r'([KGTD]\d+)', cell_str)
                            if match:
                                train_info['vehicleInfo'] = match.group(1)
                        
                        # æå–æ¢æµ‹ç«™ä¿¡æ¯ï¼ˆæŸ¥æ‰¾åŒ…å«"çº¿"å’Œ"åˆ°è¾¾"çš„å†…å®¹ï¼‰
                        if 'çº¿' in cell_str and ('åˆ°è¾¾' in cell_str or 'æ¢æµ‹ç«™' in cell_str):
                            train_info['recordStation'] = cell_str
                        
                        # æå–è¿è¡Œæ–¹å‘
                        if cell_str in ['ä¸Šè¡Œ', 'ä¸‹è¡Œ']:
                            train_info['travelDirection'] = cell_str
                        
                        # æå–æ‹…å½“å±€ï¼ˆæŸ¥æ‰¾åŒ…å«"é“è·¯å±€"çš„å†…å®¹ï¼‰
                        if 'é“è·¯å±€' in cell_str:
                            train_info['bureau'] = cell_str
                        
                        # æå–å®¢æ•´æ‰€ï¼ˆæŸ¥æ‰¾åŒ…å«"æ‰€"çš„å†…å®¹ï¼Œä½†ä¸æ˜¯"å®¢æ•´æ‰€"æ ‡ç­¾æœ¬èº«ï¼‰
                        if 'æ‰€' in cell_str and cell_str != 'å®¢æ•´æ‰€' and len(cell_str) > 2:
                            train_info['section'] = cell_str
        
        # å¤„ç†ç¬¬äºŒå¼ è¡¨ï¼šè½¦è¾†ä¿¡æ¯
        if len(excel_file.sheet_names) >= 2:
            second_sheet = excel_file.sheet_names[1]
            
            # åŒæ ·ä¸ä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºåˆ—å
            df2 = pd.read_excel(file_path, sheet_name=second_sheet, header=None)
            
            # æŸ¥æ‰¾è¡¨å¤´è¡Œï¼ˆé€šå¸¸åŒ…å«"åºå·"ã€"è½¦å·"ç­‰å­—æ®µï¼‰
            header_row = -1
            seq_col = -1
            vehicle_col = -1
            
            for i, row in df2.iterrows():
                row_values = [str(cell).strip() if pd.notna(cell) else '' for cell in row]
                
                # æŸ¥æ‰¾åŒ…å«"åºå·"å’Œ"è½¦å·"çš„è¡Œ
                if any('åºå·' in val for val in row_values) and any('è½¦å·' in val for val in row_values):
                    header_row = i
                    # æ‰¾åˆ°åºå·åˆ—å’Œè½¦å·åˆ—çš„ä½ç½®
                    for j, val in enumerate(row_values):
                        if 'åºå·' in val:
                            seq_col = j
                        elif 'è½¦å·' in val:
                            vehicle_col = j
                    break
            
            # å¦‚æœæ‰¾åˆ°äº†è¡¨å¤´ï¼Œä»ä¸‹ä¸€è¡Œå¼€å§‹æå–æ•°æ®
            if header_row >= 0 and seq_col >= 0 and vehicle_col >= 0:
                for i in range(header_row + 1, len(df2)):
                    try:
                        seq_cell = df2.iloc[i, seq_col]
                        vehicle_cell = df2.iloc[i, vehicle_col]
                        
                        if pd.notna(seq_cell) and pd.notna(vehicle_cell):
                            seq = str(int(float(seq_cell)))
                            vehicle_id = str(vehicle_cell).strip()
                            
                            # ä¿®æ”¹ï¼šåŒ…å«æ‰€æœ‰è½¦å·ï¼ˆåŒ…æ‹¬XXXXXç­‰æ— æ•ˆè½¦å·ï¼‰
                            if vehicle_id:  # åªè¦è½¦å·ä¸ä¸ºç©ºå°±åŒ…å«
                                vehicle_numbers[seq] = vehicle_id
                    except Exception as e:
                        continue
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°æ ‡å‡†è¡¨å¤´ï¼Œå°è¯•ä»ç¬¬2è¡Œå¼€å§‹ï¼Œå‡è®¾ç¬¬1åˆ—æ˜¯åºå·ï¼Œç¬¬2åˆ—æ˜¯è½¦å·
                for i in range(1, len(df2)):  # è·³è¿‡ç¬¬ä¸€è¡Œï¼ˆå¯èƒ½æ˜¯è¡¨å¤´ï¼‰
                    try:
                        if len(df2.columns) >= 2:
                            seq_cell = df2.iloc[i, 0]  # ç¬¬ä¸€åˆ—ä½œä¸ºåºå·
                            vehicle_cell = df2.iloc[i, 1]  # ç¬¬äºŒåˆ—ä½œä¸ºè½¦å·
                            
                            if pd.notna(seq_cell) and pd.notna(vehicle_cell):
                                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—ï¼ˆåºå·åº”è¯¥æ˜¯æ•°å­—ï¼‰
                                try:
                                    seq = str(int(float(seq_cell)))
                                    vehicle_id = str(vehicle_cell).strip()
                                    
                                    # ä¿®æ”¹ï¼šåŒ…å«æ‰€æœ‰è½¦å·ï¼ˆåŒ…æ‹¬XXXXXç­‰æ— æ•ˆè½¦å·ï¼‰
                                    if vehicle_id:  # åªè¦è½¦å·ä¸ä¸ºç©ºå°±åŒ…å«
                                        vehicle_numbers[seq] = vehicle_id
                                except ValueError:
                                    # å¦‚æœç¬¬ä¸€åˆ—ä¸æ˜¯æ•°å­—ï¼Œè·³è¿‡è¿™ä¸€è¡Œ
                                    continue
                    except Exception as e:
                        continue
        
        return vehicle_numbers, train_info
        
    except Exception as e:
        print(f"è§£æExcelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return {}, {}

def parse_csv_file(file_path):
    """
    è§£æCSVæ–‡ä»¶ä¸­çš„è½¦è¾†ä¿¡æ¯
    
    å‚æ•°è¯´æ˜ï¼š
    :param file_path: CSVæ–‡ä»¶è·¯å¾„
    
    è¿”å›å€¼ï¼š
    :return: (è½¦è¾†ç¼–å·å­—å…¸, åˆ—è½¦åŸºæœ¬ä¿¡æ¯å­—å…¸)
    
    åŠŸèƒ½è¯´æ˜ï¼š
    ä»CSVæ–‡ä»¶ä¸­æå–è½¦è¾†ç¼–å·è¡¨å’Œåˆ—è½¦åŸºæœ¬ä¿¡æ¯
    """
    try:
        # å°è¯•ä¸åŒçš„ç¼–ç æ ¼å¼
        encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                break
            except UnicodeDecodeError:
                continue
        else:
            print(f"æ— æ³•è§£ç CSVæ–‡ä»¶: {file_path}")
            return {}, {}
        
        vehicle_numbers = {}
        train_info = {}
        
        # æŸ¥æ‰¾è½¦è¾†ä¿¡æ¯
        if 'è¾†åº' in df.columns and 'è½¦å·' in df.columns:
            for _, row in df.iterrows():
                if pd.notna(row['è¾†åº']) and pd.notna(row['è½¦å·']):
                    vehicle_numbers[str(int(row['è¾†åº']))] = str(row['è½¦å·'])
        
        # æå–åˆ—è½¦åŸºæœ¬ä¿¡æ¯
        train_info = extract_train_info_from_dataframe(df)
        
        return vehicle_numbers, train_info
        
    except Exception as e:
        print(f"è§£æCSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return {}, {}

def parse_text_file(file_path):
    """
    è§£ææ–‡æœ¬æ–‡ä»¶ä¸­çš„è½¦è¾†ä¿¡æ¯
    
    å‚æ•°è¯´æ˜ï¼š
    :param file_path: æ–‡æœ¬æ–‡ä»¶è·¯å¾„
    
    è¿”å›å€¼ï¼š
    :return: (è½¦è¾†ç¼–å·å­—å…¸, åˆ—è½¦åŸºæœ¬ä¿¡æ¯å­—å…¸)
    
    åŠŸèƒ½è¯´æ˜ï¼š
    ä»æ–‡æœ¬æ–‡ä»¶ä¸­æå–è½¦è¾†ç¼–å·è¡¨å’Œåˆ—è½¦åŸºæœ¬ä¿¡æ¯
    é€‚ç”¨äºç»“æ„åŒ–çš„æ–‡æœ¬æ•°æ®
    """
    vehicle_numbers = {}
    train_info = {}
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ä¿¡æ¯
        # æå–è½¦æ¬¡ä¿¡æ¯
        train_pattern = r'è½¦æ¬¡[ï¼š:]*\s*([A-Z]?\d+)'
        train_match = re.search(train_pattern, content)
        if train_match:
            train_info['vehicleInfo'] = train_match.group(1)
        
        # æå–æ¢æµ‹ç«™ä¿¡æ¯
        station_pattern = r'æ¢æµ‹ç«™[ï¼š:]*\s*([^\n]+)'
        station_match = re.search(station_pattern, content)
        if station_match:
            train_info['recordStation'] = station_match.group(1).strip()
        
        # æå–è¿è¡Œæ–¹å‘
        direction_pattern = r'è¿è¡Œæ–¹å‘[ï¼š:]*\s*([ä¸Šä¸‹]è¡Œ)'
        direction_match = re.search(direction_pattern, content)
        if direction_match:
            train_info['travelDirection'] = direction_match.group(1)
        
        # æå–æ‹…å½“å±€
        bureau_pattern = r'æ‹…å½“å±€[ï¼š:]*\s*([^\n]+)'
        bureau_match = re.search(bureau_pattern, content)
        if bureau_match:
            train_info['bureau'] = bureau_match.group(1).strip()
        
        # æå–å®¢æ•´æ‰€
        section_pattern = r'å®¢æ•´æ‰€[ï¼š:]*\s*([^\n]+)'
        section_match = re.search(section_pattern, content)
        if section_match:
            train_info['section'] = section_match.group(1).strip()
        
        # æå–æ€»è¾†æ•°
        total_pattern = r'æ€»è¾†æ•°[ï¼š:]*\s*(\d+)'
        total_match = re.search(total_pattern, content)
        if total_match:
            train_info['totalSequence'] = int(total_match.group(1))
        
        # æå–è½¦è¾†ç¼–å·ä¿¡æ¯ï¼ˆå‡è®¾æ ¼å¼ä¸ºï¼šåºå· è½¦å·ï¼‰
        vehicle_pattern = r'(\d+)\s+(\d{6})'
        vehicle_matches = re.findall(vehicle_pattern, content)
        for seq, vehicle_id in vehicle_matches:
            vehicle_numbers[seq] = vehicle_id
        
    except Exception as e:
        print(f"è§£ææ–‡æœ¬æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return vehicle_numbers, train_info

def extract_train_info_from_dataframe(df):
    """
    ä»DataFrameä¸­æå–åˆ—è½¦åŸºæœ¬ä¿¡æ¯
    
    å‚æ•°è¯´æ˜ï¼š
    :param df: pandas DataFrameå¯¹è±¡
    
    è¿”å›å€¼ï¼š
    :return: åˆ—è½¦åŸºæœ¬ä¿¡æ¯å­—å…¸
    
    åŠŸèƒ½è¯´æ˜ï¼š
    åœ¨DataFrameä¸­æŸ¥æ‰¾åˆ—è½¦çš„åŸºæœ¬ä¿¡æ¯å­—æ®µ
    """
    train_info = {}
    
    # å®šä¹‰è¦æŸ¥æ‰¾çš„å­—æ®µæ˜ å°„
    field_mapping = {
        'è½¦æ¬¡': 'vehicleInfo',
        'æ¢æµ‹ç«™': 'recordStation', 
        'è¿è¡Œæ–¹å‘': 'travelDirection',
        'æ‹…å½“å±€': 'bureau',
        'å®¢æ•´æ‰€': 'section',
        'æ€»è¾†æ•°': 'totalSequence'
    }
    
    # åœ¨DataFrameä¸­æŸ¥æ‰¾è¿™äº›å­—æ®µ
    for col in df.columns:
        for chinese_name, english_name in field_mapping.items():
            if chinese_name in str(col):
                # è·å–è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªéç©ºå€¼
                values = df[col].dropna()
                if not values.empty:
                    value = values.iloc[0]
                    if english_name == 'totalSequence':
                        try:
                            train_info[english_name] = int(value)
                        except:
                            pass
                    else:
                        train_info[english_name] = str(value)
    
    return train_info

def generate_num_list_string(vehicle_numbers):
    """
    æ ¹æ®è½¦è¾†ç¼–å·å­—å…¸ç”Ÿæˆnum_listæ ¼å¼çš„å­—ç¬¦ä¸²
    
    å‚æ•°è¯´æ˜ï¼š
    :param vehicle_numbers: è½¦è¾†ç¼–å·å­—å…¸ {è¾†åº: è½¦å·}
    
    è¿”å›å€¼ï¼š
    :return: æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
    
    åŠŸèƒ½è¯´æ˜ï¼š
    å°†è½¦è¾†ç¼–å·å­—å…¸è½¬æ¢ä¸ºåŸä»£ç ä¸­num_listçš„æ ¼å¼
    """
    lines = ['    """']
    
    # æŒ‰è¾†åºæ’åº
    sorted_items = sorted(vehicle_numbers.items(), key=lambda x: int(x[0]))
    
    for seq, vehicle_id in sorted_items:
        lines.append(f'    {seq}\t{vehicle_id}')
    
    lines.append('    """')
    
    return '\n'.join(lines)

def validate_train_data_completeness(train_info, vehicle_numbers, train_index):
    """
    éªŒè¯åˆ—è½¦æ•°æ®çš„å®Œæ•´æ€§
    
    å‚æ•°è¯´æ˜ï¼š
    :param train_info: åˆ—è½¦åŸºæœ¬ä¿¡æ¯å­—å…¸
    :param vehicle_numbers: è½¦è¾†ç¼–å·å­—å…¸ {è¾†åº: è½¦å·}
    :param train_index: åˆ—è½¦åºå·ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›å€¼ï¼š
    :return: (is_complete, missing_info_list)
    
    åŠŸèƒ½è¯´æ˜ï¼š
    æ£€æŸ¥åˆ—è½¦æ•°æ®æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„ä¿¡æ¯å­—æ®µ
    å¯¹æ— æ•ˆè½¦å·åªæé†’ï¼Œä¸é˜»æ­¢ä¸Šä¼ ï¼›å¯¹å…³é”®ä¿¡æ¯ç¼ºå¤±åˆ™æŠ¥é”™é˜»æ­¢ä¸Šä¼ 
    """
    missing_info = []  # ä¸¥é‡é”™è¯¯ï¼Œä¼šé˜»æ­¢ä¸Šä¼ 
    warning_info = []  # è­¦å‘Šä¿¡æ¯ï¼Œä¸é˜»æ­¢ä¸Šä¼ 
    
    # æ£€æŸ¥æ•´è½¦ä¿¡æ¯çš„å¿…éœ€å­—æ®µï¼ˆè¿™äº›ç¼ºå¤±ä¼šé˜»æ­¢ä¸Šä¼ ï¼‰
    required_train_fields = {
        'vehicleInfo': 'è½¦æ¬¡',
        'recordStation': 'æ¢æµ‹ç«™', 
        'travelDirection': 'è¿è¡Œæ–¹å‘',
        'bureau': 'æ‹…å½“å±€',
        'section': 'å®¢æ•´æ‰€'
    }
    
    print(f"\næ­£åœ¨éªŒè¯ç¬¬ {train_index} ä¸ªåˆ—è½¦çš„æ•°æ®å®Œæ•´æ€§...")
    
    # éªŒè¯æ•´è½¦ä¿¡æ¯ï¼ˆç¼ºå¤±ä¼šæŠ¥é”™ï¼‰
    for field, field_name in required_train_fields.items():
        if field not in train_info or not train_info[field] or train_info[field] in ['æœªçŸ¥', 'æœªçŸ¥ç«™ç‚¹', 'æœªçŸ¥é“è·¯å±€', 'æœªçŸ¥æ•´å¤‡æ‰€']:
            missing_info.append(f"ã€æ•´è½¦ä¿¡æ¯ã€‘ç¼ºå¤±ï¼š{field_name}")
    
    # éªŒè¯è½¦å·ä¿¡æ¯
    if not vehicle_numbers or len(vehicle_numbers) == 0:
        missing_info.append("ã€è½¦å·ä¿¡æ¯ã€‘å®Œå…¨ç¼ºå¤±ï¼šæœªæå–åˆ°ä»»ä½•è½¦è¾†ç¼–å·")
    else:
        # å®šä¹‰æ— æ•ˆè½¦å·çš„æ¨¡å¼
        invalid_vehicle_patterns = [
            'XXXXX',     # å¸¸è§çš„å ä½ç¬¦
            'xxxxx',     # å°å†™ç‰ˆæœ¬
            'X' * 5,     # 5ä¸ªX
            'X' * 6,     # 6ä¸ªX
            'æœªçŸ¥',       # ä¸­æ–‡æœªçŸ¥
            'ç©ºç™½',       # ç©ºç™½æ ‡è®°
            'æ— ',         # æ— 
            '0' * 5,     # 5ä¸ª0
            '0' * 6,     # 6ä¸ª0
        ]
        
        # æ£€æŸ¥æ— æ•ˆè½¦å·å’Œç©ºè½¦å·
        invalid_vehicles = []
        empty_vehicles = []
        valid_sequences = []
        
        for seq, vehicle_id in vehicle_numbers.items():
            vehicle_id_clean = str(vehicle_id).strip() if vehicle_id else ''
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºï¼ˆç©ºè½¦å·ç®—ä¸¥é‡é”™è¯¯ï¼‰
            if not vehicle_id_clean:
                empty_vehicles.append(seq)
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ— æ•ˆè½¦å·ï¼ˆæ— æ•ˆè½¦å·åªæ˜¯è­¦å‘Šï¼‰
            is_invalid = False
            for pattern in invalid_vehicle_patterns:
                if vehicle_id_clean.upper() == pattern.upper():
                    invalid_vehicles.append((seq, vehicle_id_clean))
                    is_invalid = True
                    break
            
            # å¦‚æœä¸æ˜¯æ— æ•ˆè½¦å·ï¼Œåˆ™è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
            if not is_invalid:
                valid_sequences.append(int(seq))
        
        # ç©ºè½¦å·ç®—ä¸¥é‡é”™è¯¯ï¼ˆä¼šé˜»æ­¢ä¸Šä¼ ï¼‰
        if empty_vehicles:
            missing_info.append(f"ã€è½¦å·ä¿¡æ¯ã€‘è½¦å·ä¸ºç©ºï¼šè¾†åº {', '.join(empty_vehicles)}")
        
        # æ— æ•ˆè½¦å·åªæ˜¯è­¦å‘Šï¼ˆä¸é˜»æ­¢ä¸Šä¼ ï¼‰
        if invalid_vehicles:
            invalid_details = [f"è¾†åº{seq}(è½¦å·:{vehicle_id})" for seq, vehicle_id in invalid_vehicles]
            warning_info.append(f"ã€è½¦å·ä¿¡æ¯ã€‘å‘ç°æ— æ•ˆè½¦å·ï¼š{', '.join(invalid_details)}")
        
        # æ£€æŸ¥æœ‰æ•ˆè½¦å·çš„è¿ç»­æ€§ï¼ˆä¸è¿ç»­åªæ˜¯è­¦å‘Šï¼‰
        if valid_sequences:
            valid_sequences.sort()
            # æ£€æŸ¥ä»1å¼€å§‹åˆ°æœ€å¤§è¾†åºæ˜¯å¦è¿ç»­
            max_seq = max(valid_sequences)
            expected_sequences = list(range(1, max_seq + 1))
            
            missing_sequences = []
            for expected_seq in expected_sequences:
                if expected_seq not in valid_sequences:
                    missing_sequences.append(expected_seq)
            
            if missing_sequences:
                warning_info.append(f"ã€è½¦å·ä¿¡æ¯ã€‘æœ‰æ•ˆè¾†åºä¸è¿ç»­ï¼šç¼ºå¤±è¾†åº {', '.join(map(str, missing_sequences))}")
    
    # æ˜¾ç¤ºéªŒè¯ç»“æœ
    has_errors = len(missing_info) > 0
    has_warnings = len(warning_info) > 0
    
    if has_errors:
        print(f"âŒ ç¬¬ {train_index} ä¸ªåˆ—è½¦æ•°æ®ä¸å®Œæ•´ï¼ˆå°†è·³è¿‡ä¸Šä¼ ï¼‰ï¼š")
        for info in missing_info:
            print(f"   - {info}")
    
    if has_warnings:
        print(f"âš ï¸  ç¬¬ {train_index} ä¸ªåˆ—è½¦æ•°æ®è­¦å‘Šï¼ˆä¸å½±å“ä¸Šä¼ ï¼‰ï¼š")
        for info in warning_info:
            print(f"   - {info}")
    
    if not has_errors and not has_warnings:
        print(f"âœ… ç¬¬ {train_index} ä¸ªåˆ—è½¦æ•°æ®å®Œæ•´")
    elif not has_errors:
        print(f"âœ… ç¬¬ {train_index} ä¸ªåˆ—è½¦æ•°æ®å¯ä»¥ä¸Šä¼ ï¼ˆæœ‰è­¦å‘Šä½†ä¸å½±å“ï¼‰")
    
    # åªæœ‰ä¸¥é‡é”™è¯¯æ‰è¿”å›Falseï¼Œè­¦å‘Šä¸å½±å“ä¸Šä¼ 
    return not has_errors, missing_info

def auto_generate_from_folders(base_directory):
    """
    è‡ªåŠ¨ä»æ–‡ä»¶å¤¹ä¸­ç”Ÿæˆåˆ—è½¦æ•°æ®
    
    å‚æ•°è¯´æ˜ï¼š
    :param base_directory: åŒ…å«åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•
    
    è¿”å›å€¼ï¼š
    :return: (num_list, public_info, images_root_list)
    
    åŠŸèƒ½è¯´æ˜ï¼š
    æ‰«ææŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰åˆ—è½¦æ–‡ä»¶å¤¹ï¼Œè‡ªåŠ¨è§£æExcelæ–‡ä»¶å¹¶ç”Ÿæˆæ‰€éœ€çš„æ•°æ®ç»“æ„
    åªæœ‰æ•°æ®å®Œæ•´çš„åˆ—è½¦æ‰ä¼šè¢«åŒ…å«åœ¨ç»“æœä¸­
    """
    num_list = []
    public_info = []
    images_root_list = []
    
    if not os.path.exists(base_directory):
        print(f"ç›®å½•ä¸å­˜åœ¨: {base_directory}")
        return num_list, public_info, images_root_list
    
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰åŒ…å«åˆ—è½¦ä¿¡æ¯çš„æ–‡ä»¶å¤¹
    def find_train_folders(directory, depth=0):
        """é€’å½’æŸ¥æ‰¾åˆ—è½¦æ–‡ä»¶å¤¹"""
        if depth > 3:  # é™åˆ¶é€’å½’æ·±åº¦ï¼Œé¿å…æ— é™é€’å½’
            return []
        
        train_folders = []
        
        try:
            for item in os.listdir(directory):
                item_path = os.path.join(directory, item)
                
                if os.path.isdir(item_path):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è½¦ä¿¡æ¯æ–‡ä»¶å¤¹ï¼ˆåŒ…å«å…³é”®è¯ï¼‰
                    keywords = ["è½¦æ¬¡åˆ—è½¦è½¦è¾†ä¿¡æ¯", "åˆ—è½¦è½¦è¾†ä¿¡æ¯", "è½¦è¾†ä¿¡æ¯"]
                    if any(keyword in item for keyword in keywords):
                        train_folders.append(item_path)
                    else:
                        # ç»§ç»­é€’å½’æŸ¥æ‰¾å­æ–‡ä»¶å¤¹
                        train_folders.extend(find_train_folders(item_path, depth + 1))
        except PermissionError:
            pass
        except Exception as e:
            pass
        
        return train_folders
    
    # æŸ¥æ‰¾æ‰€æœ‰åˆ—è½¦æ–‡ä»¶å¤¹
    train_folders = find_train_folders(base_directory)
    
    if not train_folders:
        print("æœªæ‰¾åˆ°ä»»ä½•åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹")
        return num_list, public_info, images_root_list
    
    print(f"æ‰¾åˆ° {len(train_folders)} ä¸ªåˆ—è½¦æ–‡ä»¶å¤¹ï¼Œå¼€å§‹å¤„ç†...")
    
    # ç”¨äºç»Ÿè®¡éªŒè¯ç»“æœ
    total_trains = 0
    complete_trains = 0
    incomplete_trains = []
    
    # å¤„ç†æ¯ä¸ªåˆ—è½¦æ–‡ä»¶å¤¹
    for folder_path in train_folders:
        folder_name = os.path.basename(folder_path)
        total_trains += 1
        
        try:
            # æŸ¥æ‰¾ä¿¡æ¯æ–‡ä»¶
            info_files = find_info_files(folder_path)
            
            if not info_files:
                incomplete_trains.append((total_trains, folder_name, ["æœªæ‰¾åˆ°ä¿¡æ¯æ–‡ä»¶"]))
                continue
            
            # è§£æä¿¡æ¯æ–‡ä»¶ï¼ˆä¼˜å…ˆå¤„ç†åŒ…å«"åˆ—è½¦ä¿¡æ¯"æˆ–"è½¦è¾†ä¿¡æ¯"çš„æ–‡ä»¶ï¼‰
            target_file = None
            for file_path in info_files:
                file_name = os.path.basename(file_path)
                if "åˆ—è½¦ä¿¡æ¯" in file_name or "è½¦è¾†ä¿¡æ¯" in file_name:
                    target_file = file_path
                    break
            
            if not target_file:
                target_file = info_files[0]  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šæ–‡ä»¶ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
            
            # è§£ææ–‡ä»¶å†…å®¹
            vehicle_numbers, train_info = parse_vehicle_info_from_file(target_file)
            
            # è¡¥å……ç¼ºå¤±çš„ä¿¡æ¯ï¼ˆä»æ–‡ä»¶å¤¹åç§°ä¸­æå–ï¼‰
            if 'recordStation' not in train_info or not train_info['recordStation']:
                folder_info = parse_folder_name_simple(folder_name)
                train_info.update(folder_info)
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            is_complete, missing_info = validate_train_data_completeness(train_info, vehicle_numbers, total_trains)
            
            if not is_complete:
                # æ•°æ®ä¸å®Œæ•´ï¼Œè®°å½•ä½†ä¸æ·»åŠ åˆ°ç»“æœä¸­
                incomplete_trains.append((total_trains, folder_name, missing_info))
                print(f"âš ï¸  è·³è¿‡ç¬¬ {total_trains} ä¸ªåˆ—è½¦ï¼ˆæ•°æ®ä¸å®Œæ•´ï¼‰")
                continue
            
            # æ•°æ®å®Œæ•´ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            complete_trains += 1
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨ï¼ˆè®¾ç½®é»˜è®¤å€¼ï¼‰
            default_info = {
                'totalSequence': len(vehicle_numbers)
            }
            
            for key, default_value in default_info.items():
                if key not in train_info:
                    train_info[key] = default_value
            
            # ç”Ÿæˆnum_listå­—ç¬¦ä¸²
            num_str = generate_num_list_string(vehicle_numbers)
            num_list.append(num_str)
            public_info.append(train_info)
            images_root_list.append(folder_path)
            
            print(f"âœ“ ç¬¬ {total_trains} ä¸ªåˆ—è½¦éªŒè¯é€šè¿‡: {train_info['vehicleInfo']} ({len(vehicle_numbers)}è¾†è½¦)")
            
        except Exception as e:
            incomplete_trains.append((total_trains, folder_name, [f"å¤„ç†å¼‚å¸¸: {str(e)}"]))
            print(f"âœ— ç¬¬ {total_trains} ä¸ªåˆ—è½¦å¤„ç†å¤±è´¥: {folder_name}")
            continue
    
    # æ˜¾ç¤ºéªŒè¯æ€»ç»“
    print("\n" + "="*80)
    print("ã€æ•°æ®å®Œæ•´æ€§éªŒè¯æ€»ç»“ã€‘")
    print(f"æ€»è®¡æ‰«æ: {total_trains} ä¸ªåˆ—è½¦æ–‡ä»¶å¤¹")
    print(f"æ•°æ®å®Œæ•´: {complete_trains} ä¸ªåˆ—è½¦")
    print(f"æ•°æ®ä¸å®Œæ•´: {len(incomplete_trains)} ä¸ªåˆ—è½¦")
    
    if incomplete_trains:
        print("\nâŒ æ•°æ®ä¸å®Œæ•´çš„åˆ—è½¦è¯¦æƒ…ï¼š")
        for train_index, folder_name, missing_info in incomplete_trains:
            print(f"\nç¬¬ {train_index} ä¸ªåˆ—è½¦: {folder_name}")
            for info in missing_info:
                print(f"   - {info}")
        
        print("\nâš ï¸  ä»¥ä¸Šåˆ—è½¦å› æ•°æ®ä¸å®Œæ•´å°†ä¸ä¼šè¢«ä¸Šä¼ ")
        print("ğŸ’¡ è¯·æ£€æŸ¥å¹¶è¡¥å……ç¼ºå¤±ä¿¡æ¯åé‡æ–°è¿è¡Œç¨‹åº")
    
    if complete_trains == 0:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®å®Œæ•´çš„åˆ—è½¦ï¼Œç¨‹åºå°†ä¸ä¼šè¿›è¡Œä¸Šä¼ ")
        return [], [], []
    else:
        print(f"\nâœ… å…±æœ‰ {complete_trains} ä¸ªåˆ—è½¦æ•°æ®å®Œæ•´ï¼Œå¯ä»¥è¿›è¡Œä¸Šä¼ ")
    
    print("="*80)
    return num_list, public_info, images_root_list

def parse_folder_name_simple(folder_name):
    """
    ç®€å•è§£ææ–‡ä»¶å¤¹åç§°ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
    
    å‚æ•°è¯´æ˜ï¼š
    :param folder_name: æ–‡ä»¶å¤¹åç§°
    
    è¿”å›å€¼ï¼š
    :return: æå–çš„ä¿¡æ¯å­—å…¸
    
    åŠŸèƒ½è¯´æ˜ï¼š
    å½“ä¿¡æ¯æ–‡ä»¶ä¸­æ²¡æœ‰å®Œæ•´ä¿¡æ¯æ—¶ï¼Œä»æ–‡ä»¶å¤¹åç§°ä¸­æå–åŸºæœ¬ä¿¡æ¯
    """
    info = {}
    
    # æå–è½¦æ¬¡å·
    train_pattern = r'([A-Z]?\d+)è½¦æ¬¡'
    train_match = re.search(train_pattern, folder_name)
    if train_match:
        info['vehicleInfo'] = train_match.group(1)
    
    # æå–æ–¹å‘
    if 'ä¸Šè¡Œ' in folder_name:
        info['travelDirection'] = 'ä¸Šè¡Œ'
    elif 'ä¸‹è¡Œ' in folder_name:
        info['travelDirection'] = 'ä¸‹è¡Œ'
    
    # æå–çº¿è·¯å’Œç«™ç‚¹ä¿¡æ¯
    if 'äº¬ä¹çº¿' in folder_name:
        info['recordStation'] = 'äº¬ä¹çº¿åŒ—äº¬è¥¿ä¸Šè¡Œåˆ°è¾¾'
        info['bureau'] = 'åŒ—äº¬é“è·¯å±€'
    elif 'åˆä¹çº¿' in folder_name:
        info['recordStation'] = 'åˆä¹çº¿åˆè‚¥ä¸Šè¡Œåˆ°è¾¾'
        info['bureau'] = 'ä¸Šæµ·é“è·¯å±€'
    elif 'æ²ªæ˜†çº¿' in folder_name:
        info['recordStation'] = 'æ²ªæ˜†çº¿æ­å·ä¸‹è¡Œåˆ°è¾¾'
        info['bureau'] = 'ä¸Šæµ·é“è·¯å±€'
    elif 'äº¬æ²ªçº¿' in folder_name:
        info['recordStation'] = 'äº¬æ²ªçº¿ä¸Šæµ·ä¸Šæµ·å—ä¸‹è¡Œåˆ°è¾¾'
        info['bureau'] = 'ä¸Šæµ·é“è·¯å±€'
    
    return info

def decode_num_list(num_list_str, car_num):
    """
    ä»è½¦è¾†ç¼–å·åˆ—è¡¨ä¸­æŸ¥æ‰¾æŒ‡å®šè½¦å¢å·å¯¹åº”çš„è½¦è¾†ç¼–å·
    
    å‚æ•°è¯´æ˜ï¼š
    :param num_list_str: è½¦è¾†ç¼–å·åˆ—è¡¨å­—ç¬¦ä¸²
    :param car_num: è½¦å¢å·
    
    è¿”å›å€¼ï¼š
    :return: è½¦è¾†ç¼–å·
    
    åŠŸèƒ½è¯´æ˜ï¼š
    è§£ænum_listå­—ç¬¦ä¸²ï¼ŒæŸ¥æ‰¾æŒ‡å®šè½¦å¢å·å¯¹åº”çš„è½¦è¾†ç¼–å·
    """
    lines = num_list_str.strip().split('\n')
    
    for line in lines:
        parts = line.strip().split('\t')
        if len(parts) == 2 and parts[0].strip() == car_num:
            return parts[1].strip()
    
    raise ValueError(f"è½¦å· {car_num} åœ¨åˆ—è¡¨ä¸­æœªæ‰¾åˆ°")

def upload_data_to_server(num_list, public_info, images_root_list):
    """
    ä¸Šä¼ æ•°æ®åˆ°æœåŠ¡å™¨
    
    å‚æ•°è¯´æ˜ï¼š
    :param num_list: è½¦è¾†ç¼–å·åˆ—è¡¨
    :param public_info: åˆ—è½¦åŸºæœ¬ä¿¡æ¯åˆ—è¡¨
    :param images_root_list: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨
    
    åŠŸèƒ½è¯´æ˜ï¼š
    å°†æå–çš„åˆ—è½¦æ•°æ®å’Œå›¾ç‰‡ä¸Šä¼ åˆ°åç«¯æœåŠ¡å™¨
    """
    # åç«¯APIæ¥å£åœ°å€ - ä¿®æ”¹ä¸ºæ–°çš„IPåœ°å€
    upload_url = "http://10.0.100.211:8082/api/v1/railway-vehicle"
    
    # ç›‘æ§æ–¹å‘ä¸æ•°å­—ç¼–å·çš„å¯¹åº”å…³ç³»
    direction_to_num = {
        'å³ä¾§': 0, 'å·¦ä¾§': 1, 'åº•ä¸­': 2, 'åº•å³': 3, 'åº•å·¦': 4,
    }
    
    total_uploaded = 0
    total_failed = 0
    
    # å¤„ç†æ¯ä¸ªè½¦æ¬¡çš„å›¾ç‰‡æ•°æ®
    for i, root_dir in enumerate(images_root_list):
        print(f"\næ­£åœ¨ä¸Šä¼ ç¬¬ {i+1} ä¸ªåˆ—è½¦çš„æ•°æ®...")
        
        # ä½¿ç”¨globæœç´¢æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰jpgå›¾ç‰‡æ–‡ä»¶
        from glob import glob
        images_list = glob(os.path.join(root_dir, "*.jpg"))
        images_list.sort()
        
        if not images_list:
            print(f"  âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œè·³è¿‡ç¬¬ {i+1} ä¸ªåˆ—è½¦")
            continue
        
        # åˆ›å»ºå­—å…¸ï¼Œç”¨äºæŒ‰è½¦å¢å·åˆ†ç»„å­˜å‚¨å›¾ç‰‡è·¯å¾„
        car_num_dict = {}
        
        # éå†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ŒæŒ‰è½¦å¢å·åˆ†ç»„
        for image_path in images_list:
            try:
                image_name = os.path.basename(image_path)
                car_num, direction_num = split_seq_direction(image_name)
                
                if car_num not in car_num_dict:
                    car_num_dict[car_num] = []
                
                car_num_dict[car_num].append(image_path)
            except Exception as e:
                print(f"  âš ï¸  è§£æå›¾ç‰‡æ–‡ä»¶åå¤±è´¥: {image_name} - {e}")
                continue
        
        if not car_num_dict:
            print(f"  âŒ æ— æ³•è§£æä»»ä½•å›¾ç‰‡æ–‡ä»¶åï¼Œè·³è¿‡ç¬¬ {i+1} ä¸ªåˆ—è½¦")
            continue
        
        # è·å–å½“å‰è½¦æ¬¡çš„åŸºæœ¬ä¿¡æ¯
        vehicleInfo = public_info[i]
        
        # æŒ‰è½¦å¢å·æ’åºï¼Œç¡®ä¿ä¸Šä¼ é¡ºåºæ­£ç¡®
        car_num_list = sorted(list(car_num_dict.items()), key=lambda x: int(x[0]))
        
        car_success = 0
        car_failed = 0
        
        # éå†æ¯ä¸ªè½¦å¢ï¼Œå‡†å¤‡ä¸Šä¼ æ•°æ®
        for car_num, image_paths in car_num_list:
            try:
                # è·å–è½¦è¾†ç¼–å·
                vehicle_identity = decode_num_list(num_list[i], car_num)
                
                # æ„é€ è¦ä¸Šä¼ çš„æ•°æ®å­—å…¸
                data = {
                    'recordStation': vehicleInfo['recordStation'],
                    'travelDirection': vehicleInfo['travelDirection'],
                    'vehicleInfo': vehicleInfo['vehicleInfo'],
                    'vehicleIdentity': vehicle_identity,
                    'bureau': vehicleInfo['bureau'],
                    'section': vehicleInfo['section'],
                    'vehicleSeq': car_num,
                    'totalSequence': vehicleInfo['totalSequence'],
                }
                
                # å‡†å¤‡æ–‡ä»¶ä¸Šä¼ åˆ—è¡¨
                files = []
                
                # éå†å½“å‰è½¦å¢çš„æ‰€æœ‰å›¾ç‰‡
                for image_path in image_paths:
                    f = open(image_path, 'rb')
                    files.append(('imageFiles', f))
                
                # å‘é€POSTè¯·æ±‚ä¸Šä¼ æ•°æ®å’Œæ–‡ä»¶
                response = requests.post(upload_url, data=data, files=files)
                
                # å…³é—­æ‰€æœ‰æ‰“å¼€çš„æ–‡ä»¶
                for f in files:
                    f[1].close()
                
                # æ£€æŸ¥ä¸Šä¼ ç»“æœ
                if response.status_code == 200:
                    print(f"  âœ… è½¦å¢ {car_num} (è½¦å·: {vehicle_identity}) ä¸Šä¼ æˆåŠŸ")
                    car_success += 1
                    total_uploaded += 1
                else:
                    print(f"  âŒ è½¦å¢ {car_num} (è½¦å·: {vehicle_identity}) ä¸Šä¼ å¤±è´¥: {response.text}")
                    car_failed += 1
                    total_failed += 1
                    
            except ValueError as e:
                print(f"  âŒ è½¦å¢ {car_num} è·³è¿‡ä¸Šä¼ : {e}")
                car_failed += 1
                total_failed += 1
            except Exception as e:
                print(f"  âŒ è½¦å¢ {car_num} ä¸Šä¼ å¼‚å¸¸: {e}")
                car_failed += 1
                total_failed += 1
        
        print(f"  ç¬¬ {i+1} ä¸ªåˆ—è½¦ä¸Šä¼ å®Œæˆ: æˆåŠŸ {car_success} è¾†ï¼Œå¤±è´¥ {car_failed} è¾†")
    
    # ä¸Šä¼ æ€»ç»“
    print("\n" + "="*80)
    print("ä¸Šä¼ å®Œæˆï¼")
    print(f"æ€»è®¡ä¸Šä¼ æˆåŠŸ: {total_uploaded} è¾†è½¦")
    print(f"æ€»è®¡ä¸Šä¼ å¤±è´¥: {total_failed} è¾†è½¦")
    
    if total_failed > 0:
        print("\nâš ï¸  éƒ¨åˆ†æ•°æ®ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   2. æœåŠ¡å™¨åœ°å€æ˜¯å¦æ­£ç¡®")
        print("   3. è½¦å·ä¿¡æ¯æ˜¯å¦å®Œæ•´")

def main():
    """
    ä¸»å‡½æ•°ï¼šè‡ªåŠ¨ç”Ÿæˆå¹¶å¤„ç†åˆ—è½¦æ•°æ®
    
    åŠŸèƒ½è¯´æ˜ï¼š
    1. ä»æ–‡ä»¶å¤¹ä¸­çš„ä¿¡æ¯æ–‡ä»¶è‡ªåŠ¨æå–æ•°æ®
    2. ç”Ÿæˆnum_listã€public_infoã€images_root_list
    3. æŒ‰é¡ºåºè¾“å‡ºï¼šæ•´è½¦ä¿¡æ¯ -> è½¦å·ä¿¡æ¯ -> å›¾ç‰‡ä¿¡æ¯
    4. ä¸Šä¼ æ•°æ®åˆ°æœåŠ¡å™¨
    """
    # è®¾ç½®åˆ—è½¦æ•°æ®çš„æ ¹ç›®å½•
    base_dir = r"D:\tvds-system\TVæ•…éšœåŠå…¨åˆ—å›¾ç‰‡"
    
    print("å¼€å§‹è‡ªåŠ¨æ‰«æå’Œç”Ÿæˆåˆ—è½¦æ•°æ®...")
    
    try:
        # è‡ªåŠ¨ç”Ÿæˆæ•°æ®
        num_list, public_info, images_root_list = auto_generate_from_folders(base_dir)
        
        if not images_root_list:
            print("æœªæ‰¾åˆ°ä»»ä½•åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹")
            return
        
        print(f"\næˆåŠŸæå– {len(images_root_list)} ä¸ªåˆ—è½¦çš„ä¿¡æ¯")
        print("="*80)
        
        # éå†æ¯ä¸ªåˆ—è½¦ï¼ŒæŒ‰é¡ºåºè¾“å‡ºä¿¡æ¯
        for i, info in enumerate(public_info):
            print(f"\nç¬¬ {i+1} ä¸ªåˆ—è½¦ä¿¡æ¯ï¼š")
            print("-"*50)
            
            # 1. å…ˆè·å–æ•´è½¦ä¿¡æ¯
            print("ã€æ•´è½¦ä¿¡æ¯ã€‘")
            print(f"  è½¦æ¬¡ï¼š{info['vehicleInfo']}")
            print(f"  æ¢æµ‹ç«™ï¼š{info['recordStation']}")
            print(f"  è¿è¡Œæ–¹å‘ï¼š{info['travelDirection']}")
            print(f"  æ‹…å½“å±€ï¼š{info['bureau']}")
            print(f"  å®¢æ•´æ‰€ï¼š{info['section']}")
            if 'totalSequence' in info:
                print(f"  æ€»è¾†æ•°ï¼š{info['totalSequence']}")
            
            # 2. ç„¶åæ˜¯è½¦å·ä¿¡æ¯
            print("\nã€è½¦å·ä¿¡æ¯ã€‘")
            vehicle_numbers = {}
            if i < len(num_list):
                lines = num_list[i].strip().split('\n')
                for line in lines:
                    if '\t' in line:
                        parts = line.strip().split('\t')
                        if len(parts) == 2 and parts[0].isdigit():
                            vehicle_numbers[parts[0]] = parts[1]
            
            if vehicle_numbers:
                # æŒ‰è¾†åºæ’åºæ˜¾ç¤º
                sorted_vehicles = sorted(vehicle_numbers.items(), key=lambda x: int(x[0]))
                for seq_num, vehicle_id in sorted_vehicles:
                    print(f"  è¾†åº {seq_num}ï¼šè½¦å· {vehicle_id}")
                print(f"  å…±è®¡ï¼š{len(vehicle_numbers)} è¾†è½¦")
            else:
                print("  æœªæå–åˆ°è½¦å·ä¿¡æ¯")
            
            # 3. æœ€åæ˜¯å›¾ç‰‡ä¿¡æ¯
            print("\nã€å›¾ç‰‡ä¿¡æ¯ã€‘")
            if i < len(images_root_list):
                root_dir = images_root_list[i]
                # è·å–å›¾ç‰‡æ–‡ä»¶
                from glob import glob
                images_list = glob(os.path.join(root_dir, "*.jpg"))
                images_list.sort()
                
                if images_list:
                    # æŒ‰è½¦å¢å·åˆ†ç»„ç»Ÿè®¡å›¾ç‰‡
                    car_image_count = {}
                    for image_path in images_list:
                        try:
                            image_name = os.path.basename(image_path)
                            car_num, direction_num = split_seq_direction(image_name)
                            
                            if car_num not in car_image_count:
                                car_image_count[car_num] = 0
                            car_image_count[car_num] += 1
                        except Exception as e:
                            continue
                    
                    # æ˜¾ç¤ºå›¾ç‰‡ç»Ÿè®¡ä¿¡æ¯
                    if car_image_count:
                        sorted_cars = sorted(car_image_count.items(), key=lambda x: int(x[0]))
                        for car_num, count in sorted_cars:
                            print(f"  è½¦å¢ {car_num}ï¼š{count} å¼ å›¾ç‰‡")
                        print(f"  å›¾ç‰‡æ€»æ•°ï¼š{sum(car_image_count.values())} å¼ ")
                        print(f"  å›¾ç‰‡è·¯å¾„ï¼š{root_dir}")
                    else:
                        print(f"  å›¾ç‰‡æ€»æ•°ï¼š{len(images_list)} å¼ ")
                        print(f"  å›¾ç‰‡è·¯å¾„ï¼š{root_dir}")
                else:
                    print("  æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            else:
                print("  æœªæ‰¾åˆ°å›¾ç‰‡è·¯å¾„")
            
            print("="*80)
        
        # æ€»ç»“ä¿¡æ¯
        total_vehicles = sum(len(num_list[i].strip().split('\n')) for i in range(len(num_list)) if num_list[i].strip())
        print(f"\nã€æ€»ç»“ã€‘")
        print(f"æˆåŠŸå¤„ç† {len(images_root_list)} ä¸ªåˆ—è½¦")
        print(f"æ€»è®¡æå– {total_vehicles} è¾†è½¦çš„ä¿¡æ¯")
        
        # æ·»åŠ ä¸Šä¼ åŠŸèƒ½
        print("\n" + "="*80)
        print("å¼€å§‹ä¸Šä¼ æ•°æ®åˆ°æœåŠ¡å™¨...")
        upload_data_to_server(num_list, public_info, images_root_list)
        
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

# åŸæœ‰çš„è¾…åŠ©å‡½æ•°ä¿æŒä¸å˜
def split_seq_direction(name):
    """
    è§£æå›¾ç‰‡æ–‡ä»¶åï¼Œæå–è½¦å¢å·å’Œç›‘æ§æ–¹å‘ä¿¡æ¯
    ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
    """
    parts = name.split('è½¦')
    if len(parts) != 2:
        raise ValueError("æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®ï¼Œåº”åŒ…å«'è½¦'å­—")
    
    car_num = parts[0].strip()
    direction_part = parts[1].split('ç›‘æ§')[0].strip()
    
    direction_to_num = {
        'å³ä¾§': 0, 'å·¦ä¾§': 1, 'åº•ä¸­': 2, 'åº•å³': 3, 'åº•å·¦': 4,
    }
    
    direction_num = direction_to_num[direction_part]
    return car_num, direction_num

class FolderWatcher(FileSystemEventHandler):
    """
    æ–‡ä»¶å¤¹ç›‘å¬å™¨ç±»
    
    åŠŸèƒ½è¯´æ˜ï¼š
    ç›‘å¬æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹åˆ›å»ºäº‹ä»¶ï¼Œè‡ªåŠ¨å¤„ç†æ–°å¢çš„åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹
    """
    
    def __init__(self, base_directory):
        """
        åˆå§‹åŒ–ç›‘å¬å™¨
        
        å‚æ•°è¯´æ˜ï¼š
        :param base_directory: è¦ç›‘å¬çš„æ ¹ç›®å½•
        """
        self.base_directory = base_directory
        self.processed_folders = set()  # è®°å½•å·²å¤„ç†çš„æ–‡ä»¶å¤¹
        self.load_processed_folders()  # åŠ è½½å·²å¤„ç†æ–‡ä»¶å¤¹åˆ—è¡¨
    
    def load_processed_folders(self):
        """
        åŠ è½½å·²å¤„ç†çš„æ–‡ä»¶å¤¹åˆ—è¡¨
        
        åŠŸèƒ½è¯´æ˜ï¼š
        ä»è®°å½•æ–‡ä»¶ä¸­è¯»å–å·²å¤„ç†çš„æ–‡ä»¶å¤¹åˆ—è¡¨ï¼Œé¿å…é‡å¤å¤„ç†
        """
        record_file = os.path.join(self.base_directory, '.processed_folders.txt')
        if os.path.exists(record_file):
            try:
                with open(record_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        folder_path = line.strip()
                        if folder_path:
                            self.processed_folders.add(folder_path)
                print(f"å·²åŠ è½½ {len(self.processed_folders)} ä¸ªå·²å¤„ç†æ–‡ä»¶å¤¹è®°å½•")
            except Exception as e:
                print(f"åŠ è½½å·²å¤„ç†æ–‡ä»¶å¤¹è®°å½•å¤±è´¥: {e}")
    
    def save_processed_folder(self, folder_path):
        """
        ä¿å­˜å·²å¤„ç†çš„æ–‡ä»¶å¤¹åˆ°è®°å½•æ–‡ä»¶
        
        å‚æ•°è¯´æ˜ï¼š
        :param folder_path: å·²å¤„ç†çš„æ–‡ä»¶å¤¹è·¯å¾„
        
        åŠŸèƒ½è¯´æ˜ï¼š
        å°†æ–°å¤„ç†çš„æ–‡ä»¶å¤¹è·¯å¾„è¿½åŠ åˆ°è®°å½•æ–‡ä»¶ä¸­
        """
        record_file = os.path.join(self.base_directory, '.processed_folders.txt')
        try:
            with open(record_file, 'a', encoding='utf-8') as f:
                f.write(folder_path + '\n')
            self.processed_folders.add(folder_path)
        except Exception as e:
            print(f"ä¿å­˜å·²å¤„ç†æ–‡ä»¶å¤¹è®°å½•å¤±è´¥: {e}")
    
    def on_created(self, event):
        """
        æ–‡ä»¶å¤¹åˆ›å»ºäº‹ä»¶å¤„ç†
        
        å‚æ•°è¯´æ˜ï¼š
        :param event: æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶å¯¹è±¡
        
        åŠŸèƒ½è¯´æ˜ï¼š
        å½“æ£€æµ‹åˆ°æ–°æ–‡ä»¶å¤¹åˆ›å»ºæ—¶ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºåˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹å¹¶è¿›è¡Œå¤„ç†
        """
        if event.is_directory:
            folder_path = event.src_path
            folder_name = os.path.basename(folder_path)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ—è½¦ä¿¡æ¯æ–‡ä»¶å¤¹
            keywords = ["è½¦æ¬¡åˆ—è½¦è½¦è¾†ä¿¡æ¯", "åˆ—è½¦è½¦è¾†ä¿¡æ¯", "è½¦è¾†ä¿¡æ¯"]
            if any(keyword in folder_name for keyword in keywords):
                # é¿å…é‡å¤å¤„ç†
                if folder_path not in self.processed_folders:
                    print(f"\næ£€æµ‹åˆ°æ–°çš„åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹: {folder_name}")
                    # å»¶è¿Ÿå¤„ç†ï¼Œç¡®ä¿æ–‡ä»¶å¤¹å†…å®¹å®Œå…¨åˆ›å»º
                    threading.Timer(5.0, self.process_new_folder, args=[folder_path]).start()
    
    def process_new_folder(self, folder_path):
        """
        å¤„ç†æ–°å¢çš„åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹
        
        å‚æ•°è¯´æ˜ï¼š
        :param folder_path: æ–°å¢æ–‡ä»¶å¤¹çš„è·¯å¾„
        
        åŠŸèƒ½è¯´æ˜ï¼š
        å¯¹æ–°å¢çš„åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹è¿›è¡Œè§£æã€éªŒè¯å’Œä¸Šä¼ 
        """
        folder_name = os.path.basename(folder_path)
        
        try:
            print(f"å¼€å§‹å¤„ç†æ–°æ–‡ä»¶å¤¹: {folder_name}")
            
            # æŸ¥æ‰¾ä¿¡æ¯æ–‡ä»¶
            info_files = find_info_files(folder_path)
            
            if not info_files:
                print(f"âŒ æ–‡ä»¶å¤¹ {folder_name} ä¸­æœªæ‰¾åˆ°ä¿¡æ¯æ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†")
                return
            
            # è§£æä¿¡æ¯æ–‡ä»¶
            target_file = None
            for file_path in info_files:
                file_name = os.path.basename(file_path)
                if "åˆ—è½¦ä¿¡æ¯" in file_name or "è½¦è¾†ä¿¡æ¯" in file_name:
                    target_file = file_path
                    break
            
            if not target_file:
                target_file = info_files[0]
            
            # è§£ææ–‡ä»¶å†…å®¹
            vehicle_numbers, train_info = parse_vehicle_info_from_file(target_file)
            
            # è¡¥å……ç¼ºå¤±çš„ä¿¡æ¯
            if 'recordStation' not in train_info or not train_info['recordStation']:
                folder_info = parse_folder_name_simple(folder_name)
                train_info.update(folder_info)
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            is_complete, missing_info = validate_train_data_completeness(train_info, vehicle_numbers, 1)
            
            if not is_complete:
                print(f"âŒ æ–‡ä»¶å¤¹ {folder_name} æ•°æ®ä¸å®Œæ•´ï¼Œè·³è¿‡ä¸Šä¼ ")
                for info in missing_info:
                    print(f"   - {info}")
                return
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
            if 'totalSequence' not in train_info:
                train_info['totalSequence'] = len(vehicle_numbers)
            
            # ç”Ÿæˆæ•°æ®ç»“æ„
            num_str = generate_num_list_string(vehicle_numbers)
            num_list = [num_str]
            public_info = [train_info]
            images_root_list = [folder_path]
            
            print(f"âœ… æ–‡ä»¶å¤¹ {folder_name} æ•°æ®éªŒè¯é€šè¿‡ï¼Œå¼€å§‹ä¸Šä¼ ")
            print(f"   è½¦æ¬¡: {train_info['vehicleInfo']}")
            print(f"   è½¦è¾†æ•°: {len(vehicle_numbers)} è¾†")
            
            # ä¸Šä¼ æ•°æ®åˆ°æœåŠ¡å™¨
            upload_data_to_server(num_list, public_info, images_root_list)
            
            # è®°å½•å·²å¤„ç†çš„æ–‡ä»¶å¤¹
            self.save_processed_folder(folder_path)
            
            print(f"âœ… æ–‡ä»¶å¤¹ {folder_name} å¤„ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤¹ {folder_name} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

def start_folder_monitoring(base_directory):
    """
    å¯åŠ¨æ–‡ä»¶å¤¹ç›‘å¬æœåŠ¡
    
    å‚æ•°è¯´æ˜ï¼š
    :param base_directory: è¦ç›‘å¬çš„æ ¹ç›®å½•
    
    åŠŸèƒ½è¯´æ˜ï¼š
    å¯åŠ¨æ–‡ä»¶ç³»ç»Ÿç›‘å¬å™¨ï¼Œå®æ—¶ç›‘æ§æ–°å¢æ–‡ä»¶å¤¹
    """
    if not os.path.exists(base_directory):
        print(f"ç›‘å¬ç›®å½•ä¸å­˜åœ¨: {base_directory}")
        return
    
    print(f"å¼€å§‹ç›‘å¬ç›®å½•: {base_directory}")
    print("ç­‰å¾…æ–°çš„åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹...")
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘å¬")
    
    # åˆ›å»ºç›‘å¬å™¨
    event_handler = FolderWatcher(base_directory)
    observer = Observer()
    observer.schedule(event_handler, base_directory, recursive=True)
    
    # å¯åŠ¨ç›‘å¬
    observer.start()
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\nåœæ­¢ç›‘å¬...")
        observer.stop()
    
    observer.join()
    print("ç›‘å¬å·²åœæ­¢")

def process_existing_folders_once(base_directory):
    """
    ä¸€æ¬¡æ€§å¤„ç†ç°æœ‰æ–‡ä»¶å¤¹ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
    
    å‚æ•°è¯´æ˜ï¼š
    :param base_directory: åŒ…å«åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•
    
    åŠŸèƒ½è¯´æ˜ï¼š
    å¤„ç†ç›®å½•ä¸­ç°æœ‰çš„æ‰€æœ‰æ–‡ä»¶å¤¹ï¼Œå¹¶è®°å½•åˆ°å·²å¤„ç†åˆ—è¡¨ä¸­
    è¿™ä¸ªå‡½æ•°å¯ä»¥åœ¨é¦–æ¬¡å¯åŠ¨ç›‘å¬å‰è¿è¡Œï¼Œé¿å…é‡å¤å¤„ç†ç°æœ‰æ–‡ä»¶å¤¹
    """
    print("æ­£åœ¨å¤„ç†ç°æœ‰æ–‡ä»¶å¤¹...")
    
    # ä½¿ç”¨åŸæœ‰çš„æ‰¹é‡å¤„ç†åŠŸèƒ½
    num_list, public_info, images_root_list = auto_generate_from_folders(base_directory)
    
    if images_root_list:
        # ä¸Šä¼ æ•°æ®
        upload_data_to_server(num_list, public_info, images_root_list)
        
        # è®°å½•æ‰€æœ‰å·²å¤„ç†çš„æ–‡ä»¶å¤¹
        watcher = FolderWatcher(base_directory)
        for folder_path in images_root_list:
            watcher.save_processed_folder(folder_path)
        
        print(f"å·²å¤„ç†å¹¶è®°å½• {len(images_root_list)} ä¸ªç°æœ‰æ–‡ä»¶å¤¹")
    else:
        print("æœªæ‰¾åˆ°å¯å¤„ç†çš„ç°æœ‰æ–‡ä»¶å¤¹")

def main_with_monitoring():
    """
    å¸¦ç›‘å¬åŠŸèƒ½çš„ä¸»å‡½æ•°
    
    åŠŸèƒ½è¯´æ˜ï¼š
    1. å¯é€‰æ‹©ä¸€æ¬¡æ€§å¤„ç†ç°æœ‰æ–‡ä»¶å¤¹
    2. å¯åŠ¨å®æ—¶ç›‘å¬æœåŠ¡
    3. åªå¯¹æ–°å¢æ–‡ä»¶å¤¹è¿›è¡Œå¤„ç†
    """
    # è®¾ç½®åˆ—è½¦æ•°æ®çš„æ ¹ç›®å½•
    base_dir = r"D:\tvds-system\TVæ•…éšœåŠå…¨åˆ—å›¾ç‰‡"
    
    print("=" * 80)
    print("åˆ—è½¦æ•°æ®æ–‡ä»¶å¤¹ç›‘å¬æœåŠ¡")
    print("=" * 80)
    
    # è¯¢é—®æ˜¯å¦å¤„ç†ç°æœ‰æ–‡ä»¶å¤¹
    choice = input("æ˜¯å¦å…ˆå¤„ç†ç°æœ‰æ–‡ä»¶å¤¹ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
    
    if choice == 'y' or choice == 'yes':
        process_existing_folders_once(base_dir)
        print("\nç°æœ‰æ–‡ä»¶å¤¹å¤„ç†å®Œæˆï¼Œå¼€å§‹ç›‘å¬æ–°å¢æ–‡ä»¶å¤¹...\n")
    
    # å¯åŠ¨ç›‘å¬æœåŠ¡
    start_folder_monitoring(base_dir)

# ... existing code ...

# ä¿®æ”¹ç¨‹åºå…¥å£
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--monitor":
        # å¯åŠ¨ç›‘å¬æ¨¡å¼
        main_with_monitoring()
    else:
        # åŸæœ‰çš„æ‰¹é‡å¤„ç†æ¨¡å¼
        main()